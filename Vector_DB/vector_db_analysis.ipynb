{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd115954",
   "metadata": {},
   "source": [
    "General Information of the Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cfed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ed-donner/pricer-data\")\n",
    "train = dataset[\"train\"]\n",
    "\n",
    "# List all feature columns\n",
    "print(\"Available feature columns:\", train.column_names)\n",
    "\n",
    "# You can also inspect schema (data types)\n",
    "print(\"\\nSchema / Features:\")\n",
    "print(train.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where your index is saved\n",
    "save_path = \"/home/lisa/Arupreza/ShopAI/product_vector_store\"\n",
    "embedding_model = \"nomic-ai/nomic-embed-text-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model,\n",
    "    model_kwargs={\"device\": \"cuda\", \"trust_remote_code\": True},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88f1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload vectorstore\n",
    "vectorstore = FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get underlying FAISS index\n",
    "faiss_index = vectorstore.index\n",
    "\n",
    "# Number of vectors stored\n",
    "ntotal = faiss_index.ntotal\n",
    "\n",
    "# Dimensionality of vectors\n",
    "dim = faiss_index.d\n",
    "\n",
    "print(f\"✅ Vector store loaded from {save_path}\")\n",
    "print(f\"Number of vectors stored: {ntotal}\")\n",
    "print(f\"Dimensionality of each vector: {dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0815b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = faiss_index.reconstruct(0)\n",
    "\n",
    "print(f\"Vector ID: {0}\")\n",
    "print(\"Vector shape:\", len(vec))\n",
    "print(\"First 10 values:\", vec)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "doc_id = vectorstore.index_to_docstore_id[0]\n",
    "doc = vectorstore.docstore.search(doc_id)\n",
    "\n",
    "print(\"Document text snippet:\", doc.page_content[:200])\n",
    "print(\"Metadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07f770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c992c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee4ab56",
   "metadata": {},
   "source": [
    "Vector Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# -------------------\n",
    "# 1. Reload FAISS vector store\n",
    "# -------------------\n",
    "save_path = \"/home/lisa/Arupreza/ShopAI/product_vector_store\"\n",
    "embedding_model = \"nomic-ai/nomic-embed-text-v1\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model,\n",
    "    model_kwargs={\"device\": \"cuda\", \"trust_remote_code\": True},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)\n",
    "faiss_index = vectorstore.index\n",
    "\n",
    "print(\"✅ Vector store loaded with\", faiss_index.ntotal, \"vectors\")\n",
    "\n",
    "# -------------------\n",
    "# 2. Extract vectors (sample for visualization)\n",
    "# -------------------\n",
    "n_samples = 50000\n",
    "vectors = faiss_index.reconstruct_n(0, min(n_samples, faiss_index.ntotal))\n",
    "\n",
    "# -------------------\n",
    "# 3. KMeans clustering\n",
    "# -------------------\n",
    "n_clusters = 10  # tune this (try 10, 20, 50)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(vectors)\n",
    "\n",
    "# -------------------\n",
    "# 4. Dimensionality reduction for visualization\n",
    "# -------------------\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "reduced = tsne.fit_transform(vectors)\n",
    "\n",
    "# -------------------\n",
    "# 5. Plot clusters\n",
    "# -------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap=\"tab10\", s=10, alpha=0.7)\n",
    "plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "plt.title(\"Product Embeddings Clustered (t-SNE + KMeans)\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa6ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1579b016",
   "metadata": {},
   "source": [
    "Find Similer Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import json5\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# -------------------\n",
    "# 1. Schema\n",
    "# -------------------\n",
    "class ProductInfo(BaseModel):\n",
    "    product: str\n",
    "    price: float\n",
    "\n",
    "class ProductList(BaseModel):\n",
    "    items: List[ProductInfo]\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ProductList)\n",
    "\n",
    "# -------------------\n",
    "# 2. Prompt\n",
    "# -------------------\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"Extract all product names and their prices from the context below. \n",
    "\n",
    "⚠️ Rules:\n",
    "- Only output a JSON object.\n",
    "- JSON must have one key \"items\".\n",
    "- \"items\" must be an array of {{ \"product\": string, \"price\": number }}.\n",
    "- Do not include schema, explanation, or extra text.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# 3. Load vectorstore\n",
    "# -------------------\n",
    "save_path = \"/home/lisa/Arupreza/ShopAI/product_vector_store\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
    "    model_kwargs={\"device\": \"cuda\", \"trust_remote_code\": True},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(save_path, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# -------------------\n",
    "# 4. Load fine-tuned model\n",
    "# -------------------\n",
    "model_path = \"/home/lisa/Arupreza/ShopAI/price_prediction_peft/price_llama_lora/checkpoint-20000\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    return_full_text=False,   # don't echo the full prompt\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# -------------------\n",
    "# 5. JSON cleaning helpers\n",
    "# -------------------\n",
    "def clean_output(text: str) -> str:\n",
    "    \"\"\"Extract JSON-ish content and fix common issues.\"\"\"\n",
    "    matches = re.findall(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    if not matches:\n",
    "        raise ValueError(\"❌ No JSON found in output\")\n",
    "    candidate = matches[-1].strip()\n",
    "\n",
    "    # Replace single with double quotes\n",
    "    candidate = candidate.replace(\"'\", '\"')\n",
    "\n",
    "    # Ensure keys are quoted\n",
    "    candidate = re.sub(r'(\\b\\w+\\b):', r'\"\\1\":', candidate)\n",
    "\n",
    "    return candidate\n",
    "\n",
    "def safe_json_parse(text: str):\n",
    "    try:\n",
    "        return json.loads(text)  # strict\n",
    "    except Exception as e1:\n",
    "        print(\"⚠️ Standard JSON failed:\", e1)\n",
    "        try:\n",
    "            repaired = clean_output(text)\n",
    "            return json.loads(repaired)\n",
    "        except Exception as e2:\n",
    "            print(\"⚠️ Repaired JSON still failed:\", e2)\n",
    "            # final fallback: json5 (tolerates missing commas, comments, trailing commas)\n",
    "            return json5.loads(repaired)\n",
    "\n",
    "# -------------------\n",
    "# 6. Ask function\n",
    "# -------------------\n",
    "def ask(query: str, top_k: int = 3):\n",
    "    docs = vectorstore.similarity_search(query, k=top_k)\n",
    "    all_context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    final_prompt = prompt.format(context=all_context, question=query)\n",
    "    output = llm(final_prompt)\n",
    "\n",
    "    # HuggingFacePipeline returns list of dicts\n",
    "    if isinstance(output, list) and \"generated_text\" in output[0]:\n",
    "        output_text = output[0][\"generated_text\"]\n",
    "    else:\n",
    "        output_text = str(output)\n",
    "\n",
    "    # First try structured parser\n",
    "    try:\n",
    "        return parser.parse(output_text)\n",
    "    except Exception:\n",
    "        print(\"⚠️ Raw output (before cleaning):\\n\", output_text)\n",
    "        parsed = safe_json_parse(output_text)\n",
    "        return ProductList.model_validate(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# 7. Run Example\n",
    "# -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Find for me a gaming computer and give the price list?\"\n",
    "    results = ask(query, top_k=10)\n",
    "\n",
    "    print(\"\\n✅ Structured Results:\")\n",
    "    for item in results.items:\n",
    "        print(item.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18e3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538aab47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
